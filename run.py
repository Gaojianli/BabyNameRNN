# %%
from keras.utils.np_utils import to_categorical
import pickle
from tensorflow.keras.models import model_from_json
import numpy as np


def load_model_from_disk(sex, directory='./model/'):
    '''
    Restore model from disk

    ## Inputs:
    model (Keras model): model to backup
    directory (string): path to backup directory
    ## Outputs:
    loaded_model (Keras model): restored model
    loaded_trainset_infos (dict): Info of the training session of the restored model
        - total_epochs (integer): total number of epochs used to train the model
        - loss (float): up to date loss of the model
        - acc (float): up to date accuracy of the model
    loaded_trainset_utils (dict): trainset_utils (dict): utils dictionnary used to convert character to index of "one hot vector" and vice versa
        - c2i (dict): character to index
        - i2c (dict): index to character
    loaded_history (dict): history of the training session of the restored model
        - loss (float array): list of loss by epoch
        - acc (float array): list of accuracy by epoch
        - hyperparams (list): Infos regarding hyperparams
            format: (epoch, hyperparams_dict)
    '''
    prefix = "BabyNameModel-" + sex + '_'

    # load model from json
    with open(directory + prefix + 'model.json', 'r') as f:
        loaded_model_json = f.read()

    # Init model from json
    loaded_model = model_from_json(loaded_model_json)

    # load weights into new model
    loaded_model.load_weights(directory + prefix + "model_weights.h5")

    print("Loaded model from disk: ")
    loaded_model.summary()

    # init dict of files to load:
    pkl_to_load = {
        'trainset_infos': 'pkl',
        'trainset_utils': 'pkl',
        'training_infos': 'pkl',
        'history': 'pkl'
    }

    # init dict of loaded files
    loaded_files = {}

    for name, ext in pkl_to_load.items():
        with open(directory + prefix + name + '.' + ext, "rb") as f:
            loaded_files[name] = pickle.load(f)

    return (loaded_model, loaded_files)


def generate_name(
    model, trainset_infos, trainset_utils,
    name_max_length=25,
    prefix=None,
    verbose=False
):
    '''
    Generate some name with the RNN model

    ## Inputs:
    model (Keras model): 
    trainset_infos (dict): description of the dataset
        - target_group (string): cf Inputs
        - length_of_sequence (integer): size of the input sequence for the RNN model
        - number_of_chars (integer): number of unique character in the trainset
    trainset_utils (dict): utils dictionnary used to convert character to index of "one hot vector" and vice versa
        - c2i (dict): character to index
        - i2c (dict): index to character
    name_max_length (integer): max size of the generated name
    verbose (boolean): show some feedbacks
    ## Outputs:
    generated_name (string): name generated by the RNN
    (probability, gap): few numbers about this generated name
        probability: probability to generate this name (cummulative probability to select each character)
        ecart: gap between best name and this name (cummulative sum of gaps between selected character and best character)

    '''
    # Extract the number of unique character in trainset
    dict_size = trainset_infos['number_of_chars']

    # Extract the size of an input sequence
    sequence_length = trainset_infos['length_of_sequence']

    # Extract utils dictionnary to convert character to one hot index and vice versa
    i2c = trainset_utils['i2c']
    c2i = trainset_utils['c2i']

    # Extract padding character
    padding_start = trainset_infos['padding_start']

    # Init a name full of padding_start character
    if prefix == None:
        generated_name = padding_start * (sequence_length + name_max_length)
    else:
        generated_name = padding_start*(sequence_length-2) + \
            prefix+padding_start*name_max_length

    # Init counters
    probability = 1
    gap = 0

    # Generate new character from current sequence
    for i in range(name_max_length):
        # Extract current sequence from generated character
        x_char = generated_name[i:i+sequence_length]

        # Convert current sequence to one hot vector
        x_cat = np.array([[to_categorical(c2i[c], dict_size) for c in x_char]])

        # Predict new character probabilities
        # Actually this output a list of probabilities for each character
        p = model.predict(x_cat)

        # Extract the best character (and its probability)
        best_char = i2c[np.argmax(p)]
        best_char_prob = np.max(p)

        # Choose a random character index according to their probabilities (and its probability)
        new_char_index = np.random.choice(range(dict_size), p=p.ravel())
        new_char_prob = p[0][new_char_index]

        # Convert the index to an actual character
        new_char = i2c[new_char_index]

        # Update the generated name with the new character
        generated_name = generated_name[:sequence_length+i] + \
            new_char + generated_name[sequence_length+i+1:]

        # Update counters
        probability *= new_char_prob  # probabilities are multiplied
        gap += best_char_prob-new_char_prob  # gaps are summed

        # Show some feedbacks
        if verbose:
            print(
                'i={} new_char: {} ({:.3f}) [best:  {} ({:.3f}), diff: {:.3f}, prob: {:.3f}, gap: {:.3f}]'.format(
                    i,
                    new_char,
                    new_char_prob,
                    best_char,
                    best_char_prob,
                    best_char_prob-new_char_prob,
                    probability,
                    gap
                )
            )

        # Stop the prediction loop if it reached a 'padding_end' character
        if (new_char == trainset_infos['padding_end']):
            break

    # Clean the generated name
    generated_name = generated_name.strip('#*')

    # Show some feedbacks
    print('{} (probs: {:.6f}, gap: {:.6f})'.format(
        generated_name, probability, gap)) if verbose else None

    return generated_name, {'probability': probability, 'gap': gap}


# %%
# Model restore
sex = input("Is your baby a girl（1） or a boy（2）？")
if int(sex) == 1:
    sex = "Female"
else:
    sex = "Male"
loaded_model, loaded_files_dict = load_model_from_disk(sex)
print('\n## model fully loaded ! \n\n')
# %%
prefix = input("Please input first 2 letters of names:")
satisfied=False
while not satisfied:
    recommend_name,prob=generate_name(
        model=loaded_model,
        trainset_infos=loaded_files_dict['trainset_infos'],
        trainset_utils=loaded_files_dict['trainset_utils'],
        name_max_length=25,
        prefix=prefix,
        verbose=False
    )
    print("Recommended Name: {} (probs: {:.6f}, gap: {:.6f}) ".format(recommend_name,prob['probability'],prob['gap']))
    s=input("Are you satisfied?(y/n)")
    if s=='y':
        satisfied=True
    else:
        satisfied=False
# %%
